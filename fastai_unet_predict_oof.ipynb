{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from scipy import ndimage\n",
    "\n",
    "import torch as th\n",
    "th.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "TRAIN = '../input/train_v2/'\n",
    "TEST = '../input/test_v2/'\n",
    "SEGMENTATION = '../input/train_ship_segmentations_v2.csv.zip'\n",
    "DETECTION_TEST_PRED = '../result/ship_detection.csv'\n",
    "folds = pd.read_csv('../input/folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = 2   #number of workers for data loader\n",
    "arch = resnet34 #specify target architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = [f for f in os.listdir(TEST)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_empty(names):\n",
    "    return [name for name in names \n",
    "            if(type(segmentation_df.loc[name]['EncodedPixels']) != float)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img_id, df):\n",
    "    shape = (768,768)\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return img.reshape(shape)\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    for mask in masks:\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        if self.sz == 768: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        mask = np.zeros((768,768), dtype=np.uint8) if (self.path == TEST) \\\n",
    "            else get_mask(self.fnames[i], self.segmentation_df)\n",
    "        img = Image.fromarray(mask).resize((self.sz, self.sz)).convert('RGB')\n",
    "        return np.array(img).astype(np.float32)\n",
    "    \n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs,tr_n, val_n):\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS)\n",
    "    tr_names = tr_n if (len(tr_n_cut)%bs == 0) else tr_n[:-(len(tr_n_cut)%bs)] #cut incomplete batch\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), \n",
    "                (val_n_cut,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md\n",
    "\n",
    "def get_data_val(sz,bs, tr_n, val_n):\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS)\n",
    "    tr_names = tr_n if (len(tr_n)%bs == 0) else tr_n[:-(len(tr_n)%bs)] #cut incomplete batch\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), \n",
    "                (val_n,TRAIN), tfms, test=(val_n,TRAIN))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut,lr_cut = model_meta[arch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base(pre=True):              #load ResNet34 model\n",
    "    layers = cut_model(arch(pre), cut)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='Unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(pred, targs):\n",
    "    pred = (pred > 0.5).astype(float)\n",
    "    if pred.shape != targs.shape:\n",
    "        pred = cv2.resize(pred, (targs.shape[0], targs.shape[1]))\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(pred, true):\n",
    "    n_th = 10\n",
    "    b = 4\n",
    "    thresholds = [0.5 + 0.05*i for i in range(n_th)]\n",
    "    n_masks = len(true)\n",
    "    n_pred = len(pred)\n",
    "    ious = []\n",
    "    score = 0\n",
    "    for mask in true:\n",
    "        buf = []\n",
    "        for p in pred: buf.append(IoU(p,mask))\n",
    "        ious.append(buf)\n",
    "    for t in thresholds:   \n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for i in range(n_masks):\n",
    "            match = False\n",
    "            for j in range(n_pred):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if not match: fn += 1\n",
    "        \n",
    "        for j in range(n_pred):\n",
    "            match = False\n",
    "            for i in range(n_masks):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if match: tp += 1\n",
    "            else: fp += 1\n",
    "        score += ((b+1)*tp)/((b+1)*tp + b*fn + fp)       \n",
    "    return score/n_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask(mask):\n",
    "    threshold = 0.5\n",
    "    threshold_obj = 0 #ignor predictions composed of \"threshold_obj\" pixels or less\n",
    "    labled,n_objs = ndimage.label(mask > threshold)\n",
    "    result = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        if(obj.sum() > threshold_obj): result.append(obj)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_ind(img_id, df, shape = (768,768)): #return mask for each ship\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return []\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    result = []\n",
    "    for mask in masks:\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "        result.append(img.reshape(shape).T)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score_eval():\n",
    "    def __init__(self):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        self.score, self.count = 0.0, 0\n",
    "        \n",
    "    def put(self,pred,name):\n",
    "        true = get_mask_ind(name, self.segmentation_df)\n",
    "        self.score += get_score(pred,true)\n",
    "        self.count += 1\n",
    "        \n",
    "    def evaluate(self):\n",
    "        return self.score/self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_unit(x,fwd=True,mask=False):\n",
    "    return x\n",
    "\n",
    "def aug_flipV(x,fwd=True,mask=False):\n",
    "    return x.flip(2) if mask else x.flip(3)\n",
    "\n",
    "def aug_flipH(x,fwd=True,mask=False):\n",
    "    return x.flip(1) if mask else x.flip(2)\n",
    "\n",
    "def aug_T(x,fwd=True,mask=False):\n",
    "    return torch.transpose(x,1,2) if mask else torch.transpose(x,2,3)\n",
    "\n",
    "def aug_rot_2(x,fwd=True,mask=False): #rotate pi/2\n",
    "    return aug_flipV(aug_flipH(x,fwd,mask),fwd,mask)\n",
    "\n",
    "def aug_rot_4cr(x,fwd=True,mask=False): #rotate pi/4 counterclockwise\n",
    "    return aug_flipV(aug_T(x,fwd,mask),fwd,mask) if fwd else \\\n",
    "        aug_T(aug_flipV(x,fwd,mask),fwd,mask)\n",
    "\n",
    "def aug_rot_4cw(x,fwd=True,mask=False): #rotate pi/4 clockwise\n",
    "    return aug_flipH(aug_T(x,fwd,mask),fwd,mask) if fwd else \\\n",
    "        aug_T(aug_flipH(x,fwd,mask),fwd,mask)\n",
    "\n",
    "def aug_rot_2T(x,fwd=True,mask=False): #transpose and rotate pi/2\n",
    "    return aug_rot_2(aug_T(x,fwd,mask),fwd,mask)\n",
    "\n",
    "trms_side_on = [aug_unit,aug_flipH]\n",
    "trms_top_down = [aug_unit,aug_flipV]\n",
    "trms_dihedral = [aug_unit,aug_flipH,aug_flipV,aug_T,aug_rot_2,aug_rot_2T,\n",
    "                 aug_rot_4cw,aug_rot_4cr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_img(img):\n",
    "    return torch.transpose(torch.tensor(img),0,2).unsqueeze(0)\n",
    "\n",
    "def dec_img(img):\n",
    "    return to_np(torch.transpose(img.squeeze(0),0,2))\n",
    "\n",
    "def display_augs(x,augs=aug_unit):\n",
    "    columns = 4\n",
    "    n = len(augs)\n",
    "    rows = n//4 + 1\n",
    "    fig=plt.figure(figsize=(columns*4, rows*4))\n",
    "    img = enc_img(x)\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = j+i*columns\n",
    "            if idx >= n: break\n",
    "            fig.add_subplot(rows, columns, idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(dec_img(augs[idx](img)))\n",
    "    plt.show()\n",
    "    \n",
    "# img = np.array(Image.open(os.path.join(TRAIN,'ce69faa4b.jpg')))\n",
    "# display_augs(img,trms_dihedral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(learner, dl, F_save): #if use train dl, disable shuffling\n",
    "    learner.model.eval();\n",
    "    name_list = dl.dataset.fnames\n",
    "    num_batchs = len(dl)\n",
    "    t = tqdm(iter(dl), leave=False, total=num_batchs)\n",
    "    count = 0\n",
    "    for x,y in t:\n",
    "        py = to_np(torch.sigmoid(learn.model(V(x))))\n",
    "        batch_size = len(py)\n",
    "        for i in range(batch_size):\n",
    "            F_save(py[i],to_np(y[i]),name_list[count])\n",
    "            count += 1\n",
    "            \n",
    "def pred_aug(x,aug=[aug_unit]):\n",
    "    pred = []\n",
    "    for aug_cur in aug:\n",
    "        py = to_np(aug_cur(torch.sigmoid(learn.model(V(aug_cur(x)))),\n",
    "                           fwd=False, mask=True))\n",
    "        pred.append(py)\n",
    "    pred = np.stack(pred, axis=0).mean(axis=0)\n",
    "    return pred\n",
    "\n",
    "#if use train dl, disable shuffling\n",
    "def model_pred_aug(learner, dl, F_save, aug=[aug_unit]):\n",
    "    learner.model.eval();\n",
    "    name_list = dl.dataset.fnames\n",
    "    num_batchs = len(dl)\n",
    "    t = tqdm(iter(dl), leave=False, total=num_batchs)\n",
    "    count = 0\n",
    "    for x,y in t:\n",
    "        pred = pred_aug(x,aug)           \n",
    "        batch_size = len(pred)\n",
    "        for i in range(batch_size):\n",
    "            F_save(pred[i],to_np(y[i]),name_list[count])\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_mask(mask, shape=(768, 768)):\n",
    "    pixels = mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def enc_test(yp, y, name):\n",
    "    masks = split_mask(yp)\n",
    "    if(len(masks) == 0): \n",
    "        ship_list_dict.append({'ImageId':name,'EncodedPixels':np.nan})\n",
    "    for mask in masks:\n",
    "        mask = (cv2.resize(mask.astype(np.float), (768,768)) > 0.5)\n",
    "        ship_list_dict.append({'ImageId':name,'EncodedPixels':decode_mask(mask)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip fold 0\n",
      "skip fold 1\n",
      "skip fold 2\n",
      "load from best_res34_768_fold3\n",
      "load from best_res34_768_fold4_end                     \n",
      "                                                       \r"
     ]
    }
   ],
   "source": [
    "fold_path = [\n",
    "    (0, 'best_res34_768_fold0'),\n",
    "    (1, 'best_res34_768_fold1'),\n",
    "    (2, 'best_res34_768_fold2'),\n",
    "    (3, 'best_res34_768_fold3'),\n",
    "    (4, 'best_res34_768_fold4_end'),\n",
    "]\n",
    "\n",
    "oof_folds = [3,4]\n",
    "for i, path in fold_path:\n",
    "    if i not in oof_folds:\n",
    "        print('skip fold', i)\n",
    "        continue\n",
    "    \n",
    "    tr_n = folds.loc[folds.fold != i, 'ImageId'].values.tolist()\n",
    "    val_n = folds.loc[folds.fold == i, 'ImageId'].values.tolist()\n",
    "    \n",
    "    m = to_gpu(Unet34(get_base(False)))\n",
    "    models = UnetModel(m)\n",
    "\n",
    "    sz = 768 #image size\n",
    "    bs = 4  #batch size\n",
    "    md = get_data_val(sz,bs, tr_n, val_n)\n",
    "    \n",
    "    learn = ConvLearner(md, models)\n",
    "    print('load from', path)\n",
    "    learn.load(path)\n",
    "    learn.models_path = PATH\n",
    "    \n",
    "    ship_list_dict = []\n",
    "    model_pred_aug(learn, md.test_dl, enc_test, trms_dihedral)\n",
    "    pred_df = pd.DataFrame(ship_list_dict)\n",
    "    pred_df.to_csv('../result/oof_fold{}.csv'.format(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
